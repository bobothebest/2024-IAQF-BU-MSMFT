{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaozhezhang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| market_category | feature_name | id |\n",
    "|-----------------|--------------|----|\n",
    "| Bank            | bac          |  1 |\n",
    "| Bank            | citi         |  2 |\n",
    "| Commodity       | corn         |  3 |\n",
    "| Currency        | euro         |  4 |\n",
    "| Commodity       | gold         |  5 |\n",
    "| Inflation       | infl5y       |  6 |\n",
    "| Commodity       | iyr          |  7 |\n",
    "| Currency        | pound        |  8 |\n",
    "| Commodity       | silver       |  9 |\n",
    "| Commodity       | soybns       | 10 |\n",
    "| Equity          | sp12m        | 11 |\n",
    "| Equity          | sp6m         | 12 |\n",
    "| Commodity       | wheat        | 13 |\n",
    "| Currency        | yen          | 14 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Model (Log Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Output_Data/mpd_sp500.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "# forwards filling\n",
    "df = df.fillna(method='ffill')\n",
    "# create a new df that extract the columns of SP_adj_close\tSP_lg_pr\tSP_lg_ret(%)\tVIX\n",
    "data = df[['SP_adj_close', 'SP_lg_pr', 'SP_lg_ret(%)', 'VIX']]\n",
    "\n",
    "# keep columns that have names containing f11 and f12 only\n",
    "df = df.filter(regex='f11|f12')\n",
    "\n",
    "# merge data to df merge on index\n",
    "df = pd.merge(df, data, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that has \"maturity_target\" , \"lg_change_decr\", and \"lg_change_incr\" in the column name; those are irrelevant for feature selection\n",
    "df = df[df.columns.drop(list(df.filter(regex='maturity_target')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='lg_change_decr')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='lg_change_incr')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='SP_adj_close')))]\n",
    "\n",
    "# drop SP_lg_ret(%)\t\n",
    "df = df.drop(['SP_lg_ret(%)'], axis=1)\n",
    "# df = df.drop(['SP_lg_pr'], axis=1)\n",
    "df = df.drop(['VIX'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_68028/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "# Generate lagged variables from f1_mu to SP_lg_pr\n",
    "lags = 6\n",
    "for lag in range(1, lags+1):\n",
    "    # for col in df.columns[df.columns.get_loc('f1_mu'):df.columns.get_loc('SP_lg_ret_vol')+1]:\n",
    "    # for col in df.columns[df.columns.get_loc('f1_mu'):df.columns.get_loc('VIX')+1]: \n",
    "    for col in df.columns[df.columns.get_loc('f11_mu'):df.columns.get_loc('SP_lg_pr')+1]: \n",
    "    #for col in df.columns[df.columns.get_loc('f11_mu'):df.columns.get_loc('SP_lg_ret(%)')+1]:    \n",
    "        df[f'{col}_lag{lag}'] = df[col].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged = df.copy()\n",
    "# drop NA rows\n",
    "df_lagged = df_lagged.dropna()\n",
    "\n",
    "df_lagged['Next_Week_SP_lg_pr'] = df_lagged['SP_lg_pr'].shift(-1) # align y with X for regression\n",
    "df_lagged = df_lagged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "start_colunm = df_lagged.columns.get_loc('SP_lg_pr')\n",
    "# end_column = df_lagged.columns.get_loc('VIX_lag6')\n",
    "end_column = df_lagged.columns.get_loc('SP_lg_pr_lag6')\n",
    "#end_column = df_lagged.columns.get_loc('SP_lg_ret(%)_lag6')\n",
    "\n",
    "column_index = list(range(start_colunm, end_column+1))\n",
    "\n",
    "X = df_lagged.iloc[:, column_index]\n",
    "# y = df_lagged['SP_lg_ret(%)'] \n",
    "y = df_lagged['Next_Week_SP_lg_pr']\n",
    "\n",
    "split_index = int(len(X)*0.75)\n",
    "X_train = X[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((427, 115), (143, 115), (427,), (143,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(cv=10, max_iter=10000, random_state=12345, selection='random')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a lasso regression to select features\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lassoCV = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "lassoCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample R^2:  0.99323\n",
      "\n",
      "Out of Sample R^2:  0.87946\n",
      "\n",
      "Number of features selected:  17\n",
      "                   coef\n",
      "SP_lg_pr       0.949527\n",
      "f11_kurt_lag1  0.001542\n",
      "f12_skew_lag1  0.004656\n",
      "f12_kurt_lag1  0.003915\n",
      "f11_kurt_lag2  0.000451\n",
      "f12_kurt_lag2  0.000202\n",
      "f11_p10_lag3  -0.044958\n",
      "f12_kurt_lag3 -0.005452\n",
      "f11_kurt_lag4  0.009646\n",
      "f12_kurt_lag4 -0.004280\n",
      "f11_kurt_lag5 -0.004316\n",
      "f12_skew_lag5 -0.002214\n",
      "f12_kurt_lag5 -0.001917\n",
      "f12_p10_lag5  -0.023385\n",
      "f11_skew_lag6  0.018075\n",
      "f12_kurt_lag6  0.005235\n",
      "SP_lg_pr_lag6  0.046207\n",
      "\n",
      "Out of Sample Test set evaluation:\n",
      "MSE: 0.00060, RMSE: 0.02442, MAE: 0.01839, MAPE: 0.22034\n"
     ]
    }
   ],
   "source": [
    "print(\"In Sample R^2: \", f'{lassoCV.score(X_train, y_train):.5f}')\n",
    "print()\n",
    "print(\"Out of Sample R^2: \", f'{lassoCV.score(X_test, y_test):.5f}')\n",
    "print()\n",
    "# lasso coefficients with corresponding feature names\n",
    "lasso_coef = pd.DataFrame(lassoCV.coef_, index=X.columns, columns=['coef'])\n",
    "lasso_coef = lasso_coef[lasso_coef.coef != 0]\n",
    "\n",
    "print(\"Number of features selected: \", len(lasso_coef))\n",
    "print(lasso_coef)\n",
    "\n",
    "print()\n",
    "# show the predicted value\n",
    "lass_y_pred = lassoCV.predict(X_test)\n",
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "lass_mse = mean_squared_error(y_test, lass_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, lass_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - lass_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Out of Sample Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a lasso regression to select features\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(cv=10, max_iter=10000, random_state=12345, selection='random')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoCV2 = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "lassoCV2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample R^2:  0.99293\n",
      "\n",
      "Out of Sample R^2:  0.87708\n",
      "\n",
      "Number of features selected:  7\n",
      "                    coef\n",
      "SP_lg_pr        0.214341\n",
      "SP_lg_pr_lag1   0.013958\n",
      "f12_p50_lag2    0.001356\n",
      "f12_prInc_lag2  0.001868\n",
      "f12_prInc_lag3  0.001775\n",
      "f11_prInc_lag5  0.000458\n",
      "SP_lg_pr_lag6   0.002944\n",
      "\n",
      "Test set evaluation:\n",
      "MSE: 0.00061, RMSE: 0.02466, MAE: 0.01893, MAPE: 0.22672\n"
     ]
    }
   ],
   "source": [
    "print(\"In Sample R^2: \", f'{lassoCV2.score(X_train_scaled, y_train):.5f}')\n",
    "print()\n",
    "print(\"Out of Sample R^2: \", f'{lassoCV2.score(X_test_scaled, y_test):.5f}')\n",
    "print()\n",
    "\n",
    "# lasso coefficients with corresponding feature names\n",
    "lasso_coef = pd.DataFrame(lassoCV2.coef_, index=X.columns, columns=['coef'])\n",
    "lasso_coef = lasso_coef[lasso_coef.coef != 0]\n",
    "\n",
    "print(\"Number of features selected: \", len(lasso_coef))\n",
    "print(lasso_coef)\n",
    "\n",
    "print()\n",
    "# show the predicted value\n",
    "lassCV2_y_pred = lassoCV2.predict(X_test_scaled)\n",
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "lass_mse = mean_squared_error(y_test, lassCV2_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, lassCV2_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - lassCV2_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Log Price Lasso Regression, unscalered has better result (LassoCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Initialize the LassoCV model\n",
    "lassoCV_rolling = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "\n",
    "# Initialize an empty array to store predictions\n",
    "predictions = []\n",
    "\n",
    "# initialize X_train_rolling and y_train_rolling\n",
    "X_train_rolling = X_train.copy()\n",
    "y_train_rolling = y_train.copy()\n",
    "\n",
    "# Iterate through the dataset\n",
    "for i in range(len(X_test)):\n",
    "    # Convert X_train back to a DataFrame\n",
    "    \n",
    "    \n",
    "    # Add the new observation to X_train_df and y_train\n",
    "    X_train_rolling = pd.concat([X_train_rolling, X_test.iloc[[i]]])\n",
    "    y_train_rolling = np.append(y_train_rolling, y_test[i])\n",
    "    \n",
    "    # Fit the LassoCV model with the updated training data\n",
    "    lassoCV_rolling.fit(X_train_rolling, y_train_rolling)\n",
    "    \n",
    "    # Predict the next day's y\n",
    "    next_day_prediction = lassoCV_rolling.predict(X_test.iloc[[i]])\n",
    "    \n",
    "    # Store the prediction in the array\n",
    "    predictions.append(next_day_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Test set evaluation:\n",
      "MSE: 0.00055, RMSE: 0.02348, MAE: 0.01811, MAPE: 0.21698\n"
     ]
    }
   ],
   "source": [
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# make a copy of the predictions\n",
    "Rolling_y_pred= np.array(predictions).flatten()\n",
    "lass_mse = mean_squared_error(y_test, Rolling_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, Rolling_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - Rolling_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Out of Sample Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe with index as the same date as the y_test\n",
    "Rolling_y_pred_df = pd.DataFrame(Rolling_y_pred, index=y_test.index)\n",
    "# rename to Predicted_SP_lg_pr\n",
    "Rolling_y_pred_df.columns = ['Predicted_SP_lg_pr']\n",
    "\n",
    "# merge X_test and y_test to a dataframe called test_set\n",
    "test_set = pd.merge(X_test, y_test, left_index=True, right_index=True, how='left')\n",
    "pred_test_set = pd.merge(test_set, Rolling_y_pred_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# rename Predicted_SP_lg_pr to Predicted_Next_Week_SP_lg_pr\n",
    "pred_test_set = pred_test_set.rename(columns={'Predicted_SP_lg_pr': 'Predicted_Next_Week_SP_lg_pr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_set.to_csv('Output_Data/Rolling_Predicted_SP_lg_pr.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
